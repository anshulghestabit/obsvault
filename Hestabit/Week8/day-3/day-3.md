# DAY 3 — QUANTISATION (8-bit → 4-bit → GGUF)

### Learning Outcomes
* Quantisation trade-offs
* GGUF & llama.cpp

### Exercise
Convert model to:
* 8-bit
* 4-bit
* GGUF

### Deliverables
* `/quantized/model.gguf`
* `QUANTISATION-REPORT.md`
