# DAY 2 â€” PARAMETER-EFFICIENT FINE-TUNING (LoRA / QLoRA)

### Learning Outcomes
* Fine-tune LLM on Colab
* LoRA / QLoRA

### Exercise
Fine-tune model using **QLoRA** with:
* `r=16`, `lr=2e-4`, 4-bit loading
* Verify loss optimizing and adapter weights saved

### Deliverables
* `/notebooks/lora_train.ipynb`
* `/adapters/adapter_model.bin`
* `TRAINING-REPORT.md`
